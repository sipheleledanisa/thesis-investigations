{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import jdc\n",
    "import tensorflow as tf\n",
    "from distutils.version import StrictVersion\n",
    "\n",
    "from maci.misc import logger\n",
    "from maci.misc.overrides import overrides\n",
    "from maci.misc import tf_utils\n",
    "\n",
    "from maci.learners.base import MARLAlgorithm\n",
    "\n",
    "EPS = 1e-6"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/siphelele/anaconda3/envs/masql/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/siphelele/anaconda3/envs/masql/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/siphelele/anaconda3/envs/masql/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/siphelele/anaconda3/envs/masql/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/siphelele/anaconda3/envs/masql/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/siphelele/anaconda3/envs/masql/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def adaptive_isotropic_gaussian_kernel(xs, ys, h_min=1e-3):\n",
    "    \"\"\"Gaussian kernel with dynamic bandwidth.\n",
    "    The bandwidth is adjusted dynamically to match median_distance / log(Kx).\n",
    "    See [2] for more information.\n",
    "    Args:\n",
    "        xs(`tf.Tensor`): A tensor of shape (N x Kx x D) containing N sets of Kx\n",
    "            particles of dimension D. This is the first kernel argument.\n",
    "        ys(`tf.Tensor`): A tensor of shape (N x Ky x D) containing N sets of Kx\n",
    "            particles of dimension D. This is the second kernel argument.\n",
    "        h_min(`float`): Minimum bandwidth.\n",
    "    Returns:\n",
    "        `dict`: Returned dictionary has two fields:\n",
    "            'output': A `tf.Tensor` object of shape (N x Kx x Ky) representing\n",
    "                the kernel matrix for inputs `xs` and `ys`.\n",
    "            'gradient': A 'tf.Tensor` object of shape (N x Kx x Ky x D)\n",
    "                representing the gradient of the kernel with respect to `xs`.\n",
    "    Reference:\n",
    "        [2] Qiang Liu,Dilin Wang, \"Stein Variational Gradient Descent: A General\n",
    "            Purpose Bayesian Inference Algorithm,\" Neural Information Processing\n",
    "            Systems (NIPS), 2016.\n",
    "    \"\"\"\n",
    "    Kx, D = xs.get_shape().as_list()[-2:]\n",
    "    Ky, D2 = ys.get_shape().as_list()[-2:]\n",
    "    assert D == D2\n",
    "\n",
    "    leading_shape = tf.shape(xs)[:-2]\n",
    "\n",
    "    # Compute the pairwise distances of left and right particles.\n",
    "    diff = tf.expand_dims(xs, -2) - tf.expand_dims(ys, -3)\n",
    "    # ... x Kx x Ky x D\n",
    "\n",
    "    if StrictVersion(tf.__version__) < StrictVersion('1.5.0'):\n",
    "        dist_sq = tf.reduce_sum(diff**2, axis=-1, keep_dims=False)\n",
    "    else:\n",
    "        dist_sq = tf.reduce_sum(diff**2, axis=-1, keepdims=False)\n",
    "    # ... x Kx x Ky\n",
    "\n",
    "    # Get median.\n",
    "    input_shape = tf.concat((leading_shape, [Kx * Ky]), axis=0)\n",
    "    values, _ = tf.nn.top_k(\n",
    "        input=tf.reshape(dist_sq, input_shape),\n",
    "        k=(Kx * Ky // 2 + 1),  # This is exactly true only if Kx*Ky is odd.\n",
    "        sorted=True)  # ... x floor(Ks*Kd/2)\n",
    "\n",
    "    medians_sq = values[..., -1]  # ... (shape) (last element is the median)\n",
    "\n",
    "    h = medians_sq / np.log(Kx)  # ... (shape)\n",
    "    h = tf.maximum(h, h_min)\n",
    "    h = tf.stop_gradient(h)  # Just in case.\n",
    "    h_expanded_twice = tf.expand_dims(tf.expand_dims(h, -1), -1)\n",
    "    # ... x 1 x 1\n",
    "\n",
    "    kappa = tf.exp(-dist_sq / h_expanded_twice)  # ... x Kx x Ky\n",
    "\n",
    "    # Construct the gradient\n",
    "    h_expanded_thrice = tf.expand_dims(h_expanded_twice, -1)\n",
    "    # ... x 1 x 1 x 1\n",
    "    kappa_expanded = tf.expand_dims(kappa, -1)  # ... x Kx x Ky x 1\n",
    "\n",
    "    kappa_grad = -2 * diff / h_expanded_thrice * kappa_expanded\n",
    "    # ... x Kx x Ky x D\n",
    "\n",
    "    return {\"output\": kappa, \"gradient\": kappa_grad}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def assert_shape(tensor, expected_shape):\n",
    "    tensor_shape = tensor.shape.as_list()\n",
    "    assert len(tensor_shape) == len(expected_shape)\n",
    "    assert all([a == b for a, b in zip(tensor_shape, expected_shape)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class MASQL(MARLAlgorithm):\n",
    "    def __init__(\n",
    "            self,\n",
    "            base_kwargs,\n",
    "            agent_id,\n",
    "            env,\n",
    "            pool,\n",
    "            qf,\n",
    "            target_qf,\n",
    "            policy,\n",
    "            plotter=None,\n",
    "            policy_lr=1E-3,\n",
    "            qf_lr=1E-3,\n",
    "            tau=0.01,\n",
    "            value_n_particles=16,\n",
    "            td_target_update_interval=1,\n",
    "            kernel_fn=adaptive_isotropic_gaussian_kernel,\n",
    "            kernel_n_particles=16,\n",
    "            kernel_update_ratio=0.5,\n",
    "            discount=0.99,\n",
    "            reward_scale=.1,\n",
    "            joint=False,\n",
    "            use_saved_qf=False,\n",
    "            use_saved_policy=False,\n",
    "            save_full_state=False,\n",
    "            train_qf=True,\n",
    "            train_policy=True,\n",
    "            joint_policy=True,\n",
    "            opponent_action_range=None,\n",
    "            opponent_action_range_normalize=True\n",
    "    ):\n",
    "        super(MASQL, self).__init__(**base_kwargs)\n",
    "\n",
    "\n",
    "        self._env = env\n",
    "        self._pool = pool\n",
    "        self.qf = qf\n",
    "        self.target_qf = target_qf\n",
    "        self._policy = policy\n",
    "        self.plotter = plotter\n",
    "\n",
    "        self.agent_id = agent_id\n",
    "\n",
    "        self._qf_lr = qf_lr\n",
    "        self._policy_lr = policy_lr\n",
    "        self._tau = tau\n",
    "        self._discount = discount\n",
    "        self._reward_scale = reward_scale\n",
    "        self.joint_policy = joint_policy\n",
    "        self.opponent_action_range = opponent_action_range\n",
    "        self.opponent_action_range_normalize = opponent_action_range_normalize\n",
    "\n",
    "        self.joint = joint\n",
    "        self._value_n_particles = value_n_particles\n",
    "        self._qf_target_update_interval = td_target_update_interval\n",
    "\n",
    "        self._kernel_fn = kernel_fn\n",
    "        self._kernel_n_particles = kernel_n_particles\n",
    "        self._kernel_update_ratio = kernel_update_ratio\n",
    "\n",
    "        self._save_full_state = save_full_state\n",
    "        self._train_qf = train_qf\n",
    "        self._train_policy = train_policy\n",
    "\n",
    "        self._observation_dim = self.env.observation_spaces[self.agent_id].flat_dim\n",
    "        self._action_dim = self.env.action_spaces[self.agent_id].flat_dim\n",
    "        # just for two agent case\n",
    "        self._opponent_action_dim = self.env.action_spaces.opponent_flat_dim(self.agent_id)\n",
    "\n",
    "        self._create_placeholders()\n",
    "\n",
    "        self._training_ops = []\n",
    "        self._target_ops = []\n",
    "\n",
    "        self._create_td_update()\n",
    "        self._create_svgd_update()\n",
    "        self._create_target_ops()\n",
    "\n",
    "        if use_saved_qf:\n",
    "            saved_qf_params = qf.get_param_values()\n",
    "        if use_saved_policy:\n",
    "            saved_policy_params = policy.get_param_values()\n",
    "\n",
    "        self._sess = tf_utils.get_default_session()\n",
    "        self._sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        if use_saved_qf:\n",
    "            self.qf.set_param_values(saved_qf_params)\n",
    "        if use_saved_policy:\n",
    "            self.policy.set_param_values(saved_policy_params)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%%add_to MASQL\n",
    "def _create_placeholders(self):\n",
    "        \"\"\"Create all necessary placeholders.\"\"\"\n",
    "\n",
    "        self._observations_ph = tf.placeholder(\n",
    "            tf.float32,\n",
    "            shape=[None, self._observation_dim],\n",
    "            name='observations')\n",
    "\n",
    "        self._next_observations_ph = tf.placeholder(\n",
    "            tf.float32,\n",
    "            shape=[None, self._observation_dim],\n",
    "            name='next_observations')\n",
    "\n",
    "        self._actions_pl = tf.placeholder(\n",
    "            tf.float32, shape=[None, self._action_dim],\n",
    "            name='actions_agent_{}'.format(self.agent_id))\n",
    "\n",
    "        self._opponent_actions_pl = tf.placeholder(\n",
    "            tf.float32, shape=[None, self._opponent_action_dim],\n",
    "            name='opponent_actions_agent_{}'.format(self.agent_id))\n",
    "        # self._next_actions_ph = tf.placeholder(\n",
    "        #     tf.float32, shape=[None, self._action_dim + self._opponent_action_dim],\n",
    "        #     name='next_actions_agent_{}'.format(self._agent_id))\n",
    "\n",
    "        self._rewards_pl = tf.placeholder(\n",
    "            tf.float32, shape=[None],\n",
    "            name='rewards_agent_{}'.format(self.agent_id))\n",
    "\n",
    "        self._terminals_pl = tf.placeholder(\n",
    "            tf.float32, shape=[None],\n",
    "            name='terminals_agent_{}'.format(self.agent_id))\n",
    "\n",
    "        self._annealing_pl = tf.placeholder(\n",
    "            tf.float32, shape=[],\n",
    "            name='annealing_agent_{}'.format(self.agent_id))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "%%add_to MASQL\n",
    "def _create_td_update(self):\n",
    "        \"\"\"Create a minimization operation for Q-function update.\"\"\"\n",
    "\n",
    "        with tf.variable_scope('target_agent_{}'.format(self.agent_id), reuse=tf.AUTO_REUSE):\n",
    "            # The value of the next state is approximated with uniform samples.\n",
    "            # target_actions = tf.random_uniform(\n",
    "            #     (1, self._value_n_particles, self._action_dim), *self._env.action_range)\n",
    "            # opponent_target_actions = tf.random_uniform(\n",
    "            #     (1, self._value_n_particles, self._opponent_action_dim), *self._env.action_range)\n",
    "\n",
    "            if self.opponent_action_range is None:\n",
    "                target_actions = tf.random_uniform(\n",
    "                    (1, self._value_n_particles, self._action_dim), *self._env.action_range)\n",
    "                opponent_target_actions = tf.random_uniform(\n",
    "                    (1, self._value_n_particles, self._opponent_action_dim), *self._env.action_range)\n",
    "            else:\n",
    "                target_actions = tf.random_uniform(\n",
    "                    (1, self._value_n_particles, self._action_dim), *self._env.action_range)\n",
    "                opponent_target_actions = tf.random_uniform(\n",
    "                    (1, self._value_n_particles, self._opponent_action_dim), *self._env.action_range)\n",
    "                if self.opponent_action_range_normalize:\n",
    "                    target_actions = tf.nn.softmax(target_actions, axis=-1)\n",
    "                    opponent_target_actions = tf.nn.softmax(opponent_target_actions, axis=-1)\n",
    "\n",
    "            target_actions = tf.concat([target_actions, opponent_target_actions], axis=2)\n",
    "\n",
    "            q_value_targets = self.target_qf.output_for(\n",
    "                observations=self._next_observations_ph[:, None, :],\n",
    "                actions=target_actions)\n",
    "\n",
    "            assert_shape(q_value_targets, [None, self._value_n_particles])\n",
    "\n",
    "        joint_action = tf.concat([self._actions_pl, self._opponent_actions_pl], axis=1)\n",
    "        self._q_values = self.qf.output_for(\n",
    "            self._observations_ph, joint_action, reuse=True)\n",
    "        assert_shape(self._q_values, [None])\n",
    "\n",
    "        # Equation 10:\n",
    "\n",
    "        next_value = self._annealing_pl * tf.reduce_logsumexp(q_value_targets / self._annealing_pl, axis=1)\n",
    "        # next_value = tf.reduce_logsumexp(q_value_targets, axis=1)\n",
    "        assert_shape(next_value, [None])\n",
    "\n",
    "\n",
    "        # Importance weights add just a constant to the value.\n",
    "        next_value -= tf.log(tf.cast(self._value_n_particles, tf.float32))\n",
    "        next_value += (self._action_dim + self._opponent_action_dim) * np.log(2)\n",
    "\n",
    "        # \\hat Q in Equation 11:\n",
    "        ys = tf.stop_gradient(self._reward_scale * self._rewards_pl + (\n",
    "            1 - self._terminals_pl) * self._discount * next_value)\n",
    "        assert_shape(ys, [None])\n",
    "\n",
    "        # Equation 11:\n",
    "        bellman_residual = 0.5 * tf.reduce_mean((ys - self._q_values)**2)\n",
    "        with tf.variable_scope('target_agent_{}'.format(self.agent_id), reuse=tf.AUTO_REUSE):\n",
    "            if self._train_qf:\n",
    "\n",
    "                td_train_op = tf.train.AdamOptimizer(self._qf_lr).minimize(\n",
    "                    loss=bellman_residual, var_list=self.qf.get_params_internal())\n",
    "                self._training_ops.append(td_train_op)\n",
    "\n",
    "        self._bellman_residual = bellman_residual"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "%%add_to MASQL\n",
    "def _create_svgd_update(self):\n",
    "        \"\"\"Create a minimization operation for policy update (SVGD).\"\"\"\n",
    "        # print('actions')\n",
    "        actions = self.policy.actions_for(\n",
    "            observations=self._observations_ph,\n",
    "            n_action_samples=self._kernel_n_particles,\n",
    "            reuse=True)\n",
    "        assert_shape(actions,\n",
    "                     [None, self._kernel_n_particles, self._action_dim + self._opponent_action_dim])\n",
    "\n",
    "        # SVGD requires computing two empirical expectations over actions\n",
    "        # (see Appendix C1.1.). To that end, we first sample a single set of\n",
    "        # actions, and later split them into two sets: `fixed_actions` are used\n",
    "        # to evaluate the expectation indexed by `j` and `updated_actions`\n",
    "        # the expectation indexed by `i`.\n",
    "        n_updated_actions = int(\n",
    "            self._kernel_n_particles * self._kernel_update_ratio)\n",
    "        n_fixed_actions = self._kernel_n_particles - n_updated_actions\n",
    "\n",
    "        fixed_actions, updated_actions = tf.split(\n",
    "            actions, [n_fixed_actions, n_updated_actions], axis=1)\n",
    "        fixed_actions = tf.stop_gradient(fixed_actions)\n",
    "        assert_shape(fixed_actions, [None, n_fixed_actions, self._action_dim + self._opponent_action_dim])\n",
    "        assert_shape(updated_actions,\n",
    "                     [None, n_updated_actions, self._action_dim + self._opponent_action_dim])\n",
    "        # print('target actions')\n",
    "        svgd_target_values = self.qf.output_for(\n",
    "            self._observations_ph[:, None, :], fixed_actions, reuse=True) / self._annealing_pl\n",
    "\n",
    "        # Target log-density. Q_soft in Equation 13:\n",
    "        squash_correction = tf.reduce_sum(\n",
    "            tf.log(1 - fixed_actions**2 + EPS), axis=-1)\n",
    "        log_p = svgd_target_values + squash_correction\n",
    "\n",
    "        grad_log_p = tf.gradients(log_p, fixed_actions)[0]\n",
    "        grad_log_p = tf.expand_dims(grad_log_p, axis=2)\n",
    "        grad_log_p = tf.stop_gradient(grad_log_p)\n",
    "        assert_shape(grad_log_p, [None, n_fixed_actions, 1, self._action_dim + self._opponent_action_dim])\n",
    "\n",
    "        kernel_dict = self._kernel_fn(xs=fixed_actions, ys=updated_actions)\n",
    "\n",
    "        # Kernel function in Equation 13:\n",
    "        kappa = tf.expand_dims(kernel_dict[\"output\"], dim=3)\n",
    "        assert_shape(kappa, [None, n_fixed_actions, n_updated_actions, 1])\n",
    "\n",
    "        # Stein Variational Gradient in Equation 13:\n",
    "        action_gradients = tf.reduce_mean(\n",
    "            kappa * grad_log_p + kernel_dict[\"gradient\"], reduction_indices=1)\n",
    "        assert_shape(action_gradients,\n",
    "                     [None, n_updated_actions, self._action_dim + self._opponent_action_dim])\n",
    "\n",
    "        # Propagate the gradient through the policy network (Equation 14).\n",
    "        gradients = tf.gradients(\n",
    "            updated_actions,\n",
    "            self.policy.get_params_internal(),\n",
    "            grad_ys=action_gradients)\n",
    "\n",
    "        surrogate_loss = tf.reduce_sum([\n",
    "            tf.reduce_sum(w * tf.stop_gradient(g))\n",
    "            for w, g in zip(self.policy.get_params_internal(), gradients)\n",
    "        ])\n",
    "        with tf.variable_scope('policy_opt_agent_{}'.format(self.agent_id), reuse=tf.AUTO_REUSE):\n",
    "            if self._train_policy:\n",
    "                optimizer = tf.train.AdamOptimizer(self._policy_lr)\n",
    "                svgd_training_op = optimizer.minimize(\n",
    "                    loss=-surrogate_loss,\n",
    "                    var_list=self.policy.get_params_internal())\n",
    "                self._training_ops.append(svgd_training_op)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "%%add_to MASQL\n",
    "def _create_target_ops(self):\n",
    "        \"\"\"Create tensorflow operation for updating the target Q-function.\"\"\"\n",
    "        if not self._train_qf:\n",
    "            return\n",
    "\n",
    "        source_params = self.qf.get_params_internal()\n",
    "        target_params = self.target_qf.get_params_internal()\n",
    "\n",
    "        self._target_ops = [\n",
    "            tf.assign(target, (1 - self._tau) * target + self._tau * source)\n",
    "            for target, source in zip(target_params, source_params)\n",
    "        ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "%%add_to MASQL\n",
    "def train(self):\n",
    "        self._train(self.env, self.policy, self.pool)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "%%add_to MASQL\n",
    "@overrides\n",
    "def _init_training(self):\n",
    "    self._sess.run(self._target_ops)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "%%add_to MASQL\n",
    "@overrides\n",
    "def _do_training(self, iteration, batch, annealing=1.):\n",
    "    \"\"\"Run the operations for updating training and target ops.\"\"\"\n",
    "\n",
    "    feed_dict = self._get_feed_dict(batch, annealing)\n",
    "    self._sess.run(self._training_ops, feed_dict)\n",
    "    if iteration % self._qf_target_update_interval == 0 and self._train_qf:\n",
    "        self._sess.run(self._target_ops)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "%%add_to MASQL\n",
    "def _get_feed_dict(self, batch, annealing):\n",
    "    \"\"\"Construct a TensorFlow feed dictionary from a sample batch.\"\"\"\n",
    "\n",
    "    feeds = {\n",
    "            self._observations_ph: batch['observations'],\n",
    "            self._actions_pl: batch['actions'],\n",
    "            self._opponent_actions_pl: batch['opponent_actions'],\n",
    "            self._next_observations_ph: batch['next_observations'],\n",
    "            self._rewards_pl: batch['rewards'],\n",
    "            self._terminals_pl: batch['terminals'],\n",
    "            self._annealing_pl: annealing\n",
    "        }\n",
    "\n",
    "    return feeds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "%%add_to MASQL\n",
    "@overrides\n",
    "def log_diagnostics(self, batch):\n",
    "        \"\"\"Record diagnostic information.\n",
    "        Records the mean and standard deviation of Q-function and the\n",
    "        squared Bellman residual of the  s (mean squared Bellman error)\n",
    "        for a sample batch.\n",
    "        Also call the `draw` method of the plotter, if plotter is defined.\n",
    "        \"\"\"\n",
    "\n",
    "        feeds = self._get_feed_dict(batch)\n",
    "        qf, bellman_residual = self._sess.run(\n",
    "            [self._q_values, self._bellman_residual], feeds)\n",
    "\n",
    "        logger.record_tabular('qf-avg-agent-{}'.format(self.agent_id), np.mean(qf))\n",
    "        logger.record_tabular('qf-std-agent-{}'.format(self.agent_id), np.std(qf))\n",
    "        logger.record_tabular('mean-sq-bellman-error-agent-{}'.format(self.agent_id), bellman_residual)\n",
    "\n",
    "        self.policy.log_diagnostics(batch)\n",
    "        # if self.plotter:\n",
    "        #     self.plotter.draw()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "%%add_to MASQL\n",
    "@overrides\n",
    "def get_snapshot(self, epoch):\n",
    "        \"\"\"Return loggable snapshot of the SQL algorithm.\n",
    "        If `self._save_full_state == True`, returns snapshot including the\n",
    "        replay buffer. If `self._save_full_state == False`, returns snapshot\n",
    "        of policy, Q-function, and environment instances.\n",
    "        \"\"\"\n",
    "\n",
    "        state = {\n",
    "            'epoch_agent_{}'.format(self.agent_id): epoch,\n",
    "            'policy_agent_{}'.format(self.agent_id): self.policy,\n",
    "            'qf_agent_{}'.format(self.agent_id): self.qf,\n",
    "            'env_agent_{}'.format(self.agent_id): self.env,\n",
    "        }\n",
    "\n",
    "        if self._save_full_state:\n",
    "            state.update({'replay_buffer_agent_{}'.format(self.agent_id): self.pool})\n",
    "\n",
    "        return state"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from maci.learners import MASQL\n",
    "from maci.misc.sampler import MASampler\n",
    "from maci.environments import PBeautyGame, DifferentialGame\n",
    "from maci.environments import make_particle_env\n",
    "from maci.misc import logger\n",
    "import gtimer as gt\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "from maci.get_agents import masql_agent\n",
    "\n",
    "import maci.misc.tf_utils as U\n",
    "import os\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "parser = argparse.ArgumentParser(\"Reinforcement Learning experiments for multiagent environments\")\n",
    "# Environment\n",
    "# ['particle-simple_spread', 'particle-simple_adversary', 'particle-simple_tag', 'particle-simple_push']\n",
    "# matrix-prison , matrix-prison\n",
    "# pbeauty\n",
    "parser.add_argument('-g', \"--game_name\", type=str, default=\"diff-ma_softq\", help=\"name of the game\")\n",
    "parser.add_argument('-p', \"--p\", type=float, default=1.1, help=\"p\")\n",
    "parser.add_argument('-mu', \"--mu\", type=float, default=1.5, help=\"mu\")\n",
    "parser.add_argument('-r', \"--reward_type\", type=str, default=\"abs\", help=\"reward type\")\n",
    "parser.add_argument('-mp', \"--max_path_length\", type=int, default=1, help=\"reward type\")\n",
    "parser.add_argument('-ms', \"--max_steps\", type=int, default=20000, help=\"reward type\")\n",
    "\n",
    "parser.add_argument('-me', \"--memory\", type=int, default=0, help=\"reward type\")\n",
    "parser.add_argument('-n', \"--n\", type=int, default=2, help=\"name of the game\")\n",
    "parser.add_argument('-bs', \"--batch_size\", type=int, default=64, help=\"name of the game\")\n",
    "parser.add_argument('-hm', \"--hidden_size\", type=int, default=100, help=\"name of the game\")\n",
    "parser.add_argument('-re', \"--repeat\", type=bool, default=False, help=\"name of the game\")\n",
    "parser.add_argument('-a', \"--aux\", type=bool, default=True, help=\"name of the game\")\n",
    "parser.add_argument('-m', \"--model_names_setting\", type=str, default='MASQL_MASQL', help=\"models setting agent vs adv\")\n",
    "arglist, unknown = parser.parse_known_args()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "\n",
    "game_name = arglist.game_name\n",
    "# 'abs', 'one'\n",
    "reward_type = arglist.reward_type\n",
    "p = arglist.p\n",
    "agent_num = arglist.n\n",
    "u_range = 1.\n",
    "k = 0\n",
    "model_names_setting = arglist.model_names_setting.split('_')\n",
    "model_names = [model_names_setting[0]] + [model_names_setting[1]] * (agent_num - 1)\n",
    "model_name = '_'.join(model_names)\n",
    "path_prefix = game_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "diff_game_name = game_name.split('-')[-1]\n",
    "agent_num = 2\n",
    "env = DifferentialGame(diff_game_name, agent_num)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime('%Y-%m-%d %H:%M:%S.%f %Z')\n",
    "if 'CG' in model_name:\n",
    "    model_name = model_name + '-{}'.format(arglist.mu)\n",
    "if not arglist.aux:\n",
    "    model_name = model_name + '-{}'.format(arglist.aux)\n",
    "\n",
    "suffix = '{}/{}/{}/{}'.format(path_prefix, agent_num, model_name, timestamp)\n",
    "\n",
    "print(suffix)\n",
    "\n",
    "logger.add_tabular_output('./log/{}.csv'.format(suffix))\n",
    "snapshot_dir = './snapshot/{}'.format(suffix)\n",
    "policy_dir = './policy/{}'.format(suffix)\n",
    "os.makedirs(snapshot_dir, exist_ok=True)\n",
    "os.makedirs(policy_dir, exist_ok=True)\n",
    "logger.set_snapshot_dir(snapshot_dir)\n",
    "\n",
    "agents = []\n",
    "M = arglist.hidden_size\n",
    "batch_size = arglist.batch_size\n",
    "sampler = MASampler(agent_num=agent_num, joint=True, max_path_length=30, min_pool_size=100, batch_size=batch_size)\n",
    "\n",
    "base_kwargs = {\n",
    "    'sampler': sampler,\n",
    "    'epoch_length': 1,\n",
    "    'n_epochs': arglist.max_steps,\n",
    "    'n_train_repeat': 1,\n",
    "    'eval_render': True,\n",
    "    'eval_n_episodes': 10\n",
    "}\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "diff-ma_softq/2/MASQL_MASQL/2021-07-16 12:58:03.249936 \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "with U.single_threaded_session():\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        print(i, model_name)\n",
    "        agent = masql_agent(model_name, i, env, M, u_range, base_kwargs, game_name=game_name)\n",
    "        agents.append(agent)\n",
    "    sampler.initialize(env, agents)\n",
    "\n",
    "    for agent in agents:\n",
    "        agent._init_training()\n",
    "        gt.rename_root('MARLAlgorithm')\n",
    "        gt.reset()\n",
    "        gt.set_def_unique(False)\n",
    "        initial_exploration_done = False\n",
    "        # noise = .1\n",
    "        noise = 1.\n",
    "        alpha = .5\n",
    "\n",
    "\n",
    "        for agent in agents:\n",
    "            try:\n",
    "                agent.policy.set_noise_level(noise)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        for epoch in gt.timed_for(range(base_kwargs['n_epochs'] + 1)):\n",
    "            logger.push_prefix('Epoch #%d | ' % epoch)\n",
    "            if epoch % 10 == 0:\n",
    "                print(suffix)\n",
    "            for t in range(base_kwargs['epoch_length']):\n",
    "                # TODO.code consolidation: Add control interval to sampler\n",
    "                if not initial_exploration_done:\n",
    "                    if epoch >= 1000:\n",
    "                        initial_exploration_done = True\n",
    "                sampler.sample()\n",
    "                # print('Sampling')\n",
    "                if not initial_exploration_done:\n",
    "                    continue\n",
    "                gt.stamp('sample')\n",
    "                # print('Sample Done')\n",
    "                if epoch == base_kwargs['n_epochs']:\n",
    "                    noise = 0.1\n",
    "\n",
    "                    for agent in agents:\n",
    "                        try:\n",
    "                            agent.policy.set_noise_level(noise)\n",
    "                        except:\n",
    "                            pass\n",
    "                    # alpha = .1\n",
    "                if epoch > base_kwargs['n_epochs'] / 10:\n",
    "                    noise = 0.1\n",
    "                    for agent in agents:\n",
    "                        try:\n",
    "                            agent.policy.set_noise_level(noise)\n",
    "                        except:\n",
    "                            pass\n",
    "                    # alpha = .1\n",
    "                if epoch > base_kwargs['n_epochs'] / 5:\n",
    "                    noise = 0.05\n",
    "                    for agent in agents:\n",
    "                        try:\n",
    "                            agent.policy.set_noise_level(noise)\n",
    "                        except:\n",
    "                            pass\n",
    "                if epoch > base_kwargs['n_epochs'] / 6:\n",
    "                    noise = 0.01\n",
    "                    for agent in agents:\n",
    "                        try:\n",
    "                            agent.policy.set_noise_level(noise)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                for j in range(base_kwargs['n_train_repeat']):\n",
    "                    batch_n = []\n",
    "                    recent_batch_n = []\n",
    "                    indices = None\n",
    "                    receent_indices = None\n",
    "                    for i, agent in enumerate(agents):\n",
    "                        if i == 0:\n",
    "                            batch = agent.pool.random_batch(batch_size)\n",
    "                            indices = agent.pool.indices\n",
    "                            receent_indices = list(range(agent.pool._top-batch_size, agent.pool._top))\n",
    "\n",
    "                        batch_n.append(agent.pool.random_batch_by_indices(indices))\n",
    "                        recent_batch_n.append(agent.pool.random_batch_by_indices(receent_indices))\n",
    "\n",
    "                    # print(len(batch_n))\n",
    "                    target_next_actions_n = []\n",
    "                    try:\n",
    "                        for agent, batch in zip(agents, batch_n):\n",
    "                            target_next_actions_n.append(agent._target_policy.get_actions(batch['next_observations']))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "\n",
    "                    opponent_actions_n = np.array([batch['actions'] for batch in batch_n])\n",
    "                    recent_opponent_actions_n = np.array([batch['actions'] for batch in recent_batch_n])\n",
    "\n",
    "                    ####### figure out\n",
    "                    recent_opponent_observations_n = []\n",
    "                    for batch in recent_batch_n:\n",
    "                        recent_opponent_observations_n.append(batch['observations'])\n",
    "\n",
    "\n",
    "                    current_actions = [agents[i]._policy.get_actions(batch_n[i]['next_observations'])[0][0] for i in range(agent_num)]\n",
    "                    all_actions_k = []\n",
    "                    with open('{}/policy.csv'.format(policy_dir), 'a') as f:\n",
    "                        f.write(','.join(list(map(str, current_actions)))+'\\n')\n",
    "                    for i, agent in enumerate(agents):\n",
    "                        try:\n",
    "                            batch_n[i]['next_actions'] = deepcopy(target_next_actions_n[i])\n",
    "                        except:\n",
    "                            pass\n",
    "                        batch_n[i]['opponent_actions'] = np.reshape(np.delete(deepcopy(opponent_actions_n), i, 0), (-1, agent._opponent_action_dim))\n",
    "                        if agent.joint:\n",
    "                            if agent.opponent_modelling:\n",
    "                                batch_n[i]['recent_opponent_observations'] = recent_opponent_observations_n[i]\n",
    "                                batch_n[i]['recent_opponent_actions'] = np.reshape(np.delete(deepcopy(recent_opponent_actions_n), i, 0), (-1, agent._opponent_action_dim))\n",
    "                                batch_n[i]['opponent_next_actions'] = agent.opponent_policy.get_actions(batch_n[i]['next_observations'])\n",
    "                            else:\n",
    "                                batch_n[i]['opponent_next_actions'] = np.reshape(np.delete(deepcopy(target_next_actions_n), i, 0), (-1, agent._opponent_action_dim))\n",
    "                       \n",
    "                            agent._do_training(iteration=t + epoch * agent._epoch_length, batch=batch_n[i], annealing=alpha)\n",
    "                 \n",
    "                gt.stamp('train')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 MASQL\n",
      "0 1\n",
      "stochastic 1.0 True <function tanh at 0x7f07ca6f0d90>\n",
      "stochastic 1.0 True <function tanh at 0x7f07ca6f0d90>\n",
      "WARNING:tensorflow:From /home/siphelele/Documents/thesis-investigations/code/maci/learners/masql.py:255: calling expand_dims (from tensorflow.python.ops.array_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "1 MASQL\n",
      "1 1\n",
      "stochastic 1.0 True <function tanh at 0x7f07ca6f0d90>\n",
      "stochastic 1.0 True <function tanh at 0x7f07ca6f0d90>\n",
      "diff-ma_softq/2/MASQL_MASQL/2021-07-16 12:58:03.249936 \n",
      "[-12.89696789 -12.89696789]\n",
      "2021-07-16 12:58:07.347244 SAST | ------------------------  -------\n",
      "2021-07-16 12:58:07.347673 SAST | max-path-return_agent_0   -12.897\n",
      "2021-07-16 12:58:07.348078 SAST | mean-path-return_agent_0  -12.897\n",
      "2021-07-16 12:58:07.348423 SAST | last-path-return_agent_0  -12.897\n",
      "2021-07-16 12:58:07.348752 SAST | max-path-return_agent_1   -12.897\n",
      "2021-07-16 12:58:07.349109 SAST | mean-path-return_agent_1  -12.897\n",
      "2021-07-16 12:58:07.349488 SAST | last-path-return_agent_1  -12.897\n",
      "2021-07-16 12:58:07.349801 SAST | episodes                    1\n",
      "2021-07-16 12:58:07.351356 SAST | total-samples               1\n",
      "2021-07-16 12:58:07.352068 SAST | ------------------------  -------\n",
      "[-13.48802185 -13.48802185]\n",
      "2021-07-16 12:58:07.361860 SAST | ------------------------  -------\n",
      "2021-07-16 12:58:07.362406 SAST | max-path-return_agent_0   -12.897\n",
      "2021-07-16 12:58:07.362816 SAST | mean-path-return_agent_0  -13.488\n",
      "2021-07-16 12:58:07.363209 SAST | last-path-return_agent_0  -13.488\n",
      "2021-07-16 12:58:07.363616 SAST | max-path-return_agent_1   -12.897\n",
      "2021-07-16 12:58:07.364067 SAST | mean-path-return_agent_1  -13.488\n",
      "2021-07-16 12:58:07.364464 SAST | last-path-return_agent_1  -13.488\n",
      "2021-07-16 12:58:07.364863 SAST | episodes                    2\n",
      "2021-07-16 12:58:07.365534 SAST | total-samples               2\n",
      "2021-07-16 12:58:07.366165 SAST | ------------------------  -------\n",
      "[-13.40089321 -13.40089321]\n",
      "2021-07-16 12:58:07.373986 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.374393 SAST | max-path-return_agent_0   -12.897\n",
      "2021-07-16 12:58:07.374693 SAST | mean-path-return_agent_0  -13.4009\n",
      "2021-07-16 12:58:07.374992 SAST | last-path-return_agent_0  -13.4009\n",
      "2021-07-16 12:58:07.375315 SAST | max-path-return_agent_1   -12.897\n",
      "2021-07-16 12:58:07.375695 SAST | mean-path-return_agent_1  -13.4009\n",
      "2021-07-16 12:58:07.376041 SAST | last-path-return_agent_1  -13.4009\n",
      "2021-07-16 12:58:07.376408 SAST | episodes                    3\n",
      "2021-07-16 12:58:07.376918 SAST | total-samples               3\n",
      "2021-07-16 12:58:07.377281 SAST | ------------------------  --------\n",
      "[-13.72353649 -13.72353649]\n",
      "2021-07-16 12:58:07.390299 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.390826 SAST | max-path-return_agent_0   -12.897\n",
      "2021-07-16 12:58:07.391210 SAST | mean-path-return_agent_0  -13.7235\n",
      "2021-07-16 12:58:07.391604 SAST | last-path-return_agent_0  -13.7235\n",
      "2021-07-16 12:58:07.391983 SAST | max-path-return_agent_1   -12.897\n",
      "2021-07-16 12:58:07.392324 SAST | mean-path-return_agent_1  -13.7235\n",
      "2021-07-16 12:58:07.392958 SAST | last-path-return_agent_1  -13.7235\n",
      "2021-07-16 12:58:07.393714 SAST | episodes                    4\n",
      "2021-07-16 12:58:07.394605 SAST | total-samples               4\n",
      "2021-07-16 12:58:07.395352 SAST | ------------------------  --------\n",
      "[-13.63617229 -13.63617229]\n",
      "2021-07-16 12:58:07.419508 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.420706 SAST | max-path-return_agent_0   -12.897\n",
      "2021-07-16 12:58:07.422852 SAST | mean-path-return_agent_0  -13.6362\n",
      "2021-07-16 12:58:07.423448 SAST | last-path-return_agent_0  -13.6362\n",
      "2021-07-16 12:58:07.423927 SAST | max-path-return_agent_1   -12.897\n",
      "2021-07-16 12:58:07.424350 SAST | mean-path-return_agent_1  -13.6362\n",
      "2021-07-16 12:58:07.424763 SAST | last-path-return_agent_1  -13.6362\n",
      "2021-07-16 12:58:07.425216 SAST | episodes                    5\n",
      "2021-07-16 12:58:07.425836 SAST | total-samples               5\n",
      "2021-07-16 12:58:07.426999 SAST | ------------------------  --------\n",
      "[-13.483325 -13.483325]\n",
      "2021-07-16 12:58:07.442668 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.443298 SAST | max-path-return_agent_0   -12.897\n",
      "2021-07-16 12:58:07.444127 SAST | mean-path-return_agent_0  -13.4833\n",
      "2021-07-16 12:58:07.445012 SAST | last-path-return_agent_0  -13.4833\n",
      "2021-07-16 12:58:07.446771 SAST | max-path-return_agent_1   -12.897\n",
      "2021-07-16 12:58:07.449850 SAST | mean-path-return_agent_1  -13.4833\n",
      "2021-07-16 12:58:07.450839 SAST | last-path-return_agent_1  -13.4833\n",
      "2021-07-16 12:58:07.452012 SAST | episodes                    6\n",
      "2021-07-16 12:58:07.452715 SAST | total-samples               6\n",
      "2021-07-16 12:58:07.453504 SAST | ------------------------  --------\n",
      "[-13.498456 -13.498456]\n",
      "2021-07-16 12:58:07.470985 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.471660 SAST | max-path-return_agent_0   -12.897\n",
      "2021-07-16 12:58:07.472378 SAST | mean-path-return_agent_0  -13.4985\n",
      "2021-07-16 12:58:07.472930 SAST | last-path-return_agent_0  -13.4985\n",
      "2021-07-16 12:58:07.473436 SAST | max-path-return_agent_1   -12.897\n",
      "2021-07-16 12:58:07.473955 SAST | mean-path-return_agent_1  -13.4985\n",
      "2021-07-16 12:58:07.474470 SAST | last-path-return_agent_1  -13.4985\n",
      "2021-07-16 12:58:07.475075 SAST | episodes                    7\n",
      "2021-07-16 12:58:07.475796 SAST | total-samples               7\n",
      "2021-07-16 12:58:07.476525 SAST | ------------------------  --------\n",
      "[-14.05480671 -14.05480671]\n",
      "2021-07-16 12:58:07.486830 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.487448 SAST | max-path-return_agent_0   -12.897\n",
      "2021-07-16 12:58:07.487931 SAST | mean-path-return_agent_0  -14.0548\n",
      "2021-07-16 12:58:07.488355 SAST | last-path-return_agent_0  -14.0548\n",
      "2021-07-16 12:58:07.488736 SAST | max-path-return_agent_1   -12.897\n",
      "2021-07-16 12:58:07.489110 SAST | mean-path-return_agent_1  -14.0548\n",
      "2021-07-16 12:58:07.489496 SAST | last-path-return_agent_1  -14.0548\n",
      "2021-07-16 12:58:07.489919 SAST | episodes                    8\n",
      "2021-07-16 12:58:07.491536 SAST | total-samples               8\n",
      "2021-07-16 12:58:07.493226 SAST | ------------------------  --------\n",
      "[-13.84903145 -13.84903145]\n",
      "2021-07-16 12:58:07.505906 SAST | ------------------------  -------\n",
      "2021-07-16 12:58:07.506550 SAST | max-path-return_agent_0   -12.897\n",
      "2021-07-16 12:58:07.507694 SAST | mean-path-return_agent_0  -13.849\n",
      "2021-07-16 12:58:07.509214 SAST | last-path-return_agent_0  -13.849\n",
      "2021-07-16 12:58:07.509866 SAST | max-path-return_agent_1   -12.897\n",
      "2021-07-16 12:58:07.511510 SAST | mean-path-return_agent_1  -13.849\n",
      "2021-07-16 12:58:07.512983 SAST | last-path-return_agent_1  -13.849\n",
      "2021-07-16 12:58:07.513533 SAST | episodes                    9\n",
      "2021-07-16 12:58:07.514161 SAST | total-samples               9\n",
      "2021-07-16 12:58:07.514854 SAST | ------------------------  -------\n",
      "[-12.88078308 -12.88078308]\n",
      "2021-07-16 12:58:07.550761 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.551347 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.551949 SAST | mean-path-return_agent_0  -12.8808\n",
      "2021-07-16 12:58:07.552593 SAST | last-path-return_agent_0  -12.8808\n",
      "2021-07-16 12:58:07.553135 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.553572 SAST | mean-path-return_agent_1  -12.8808\n",
      "2021-07-16 12:58:07.553985 SAST | last-path-return_agent_1  -12.8808\n",
      "2021-07-16 12:58:07.554402 SAST | episodes                   10\n",
      "2021-07-16 12:58:07.554844 SAST | total-samples              10\n",
      "2021-07-16 12:58:07.555284 SAST | ------------------------  --------\n",
      "diff-ma_softq/2/MASQL_MASQL/2021-07-16 12:58:03.249936 \n",
      "[-13.54703426 -13.54703426]\n",
      "2021-07-16 12:58:07.568336 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.569515 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.570538 SAST | mean-path-return_agent_0  -13.547\n",
      "2021-07-16 12:58:07.571422 SAST | last-path-return_agent_0  -13.547\n",
      "2021-07-16 12:58:07.572226 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.572800 SAST | mean-path-return_agent_1  -13.547\n",
      "2021-07-16 12:58:07.574053 SAST | last-path-return_agent_1  -13.547\n",
      "2021-07-16 12:58:07.574908 SAST | episodes                   11\n",
      "2021-07-16 12:58:07.575534 SAST | total-samples              11\n",
      "2021-07-16 12:58:07.576294 SAST | ------------------------  --------\n",
      "[-13.07905293 -13.07905293]\n",
      "2021-07-16 12:58:07.584906 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.586071 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.586767 SAST | mean-path-return_agent_0  -13.0791\n",
      "2021-07-16 12:58:07.587373 SAST | last-path-return_agent_0  -13.0791\n",
      "2021-07-16 12:58:07.587921 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.588555 SAST | mean-path-return_agent_1  -13.0791\n",
      "2021-07-16 12:58:07.589179 SAST | last-path-return_agent_1  -13.0791\n",
      "2021-07-16 12:58:07.590718 SAST | episodes                   12\n",
      "2021-07-16 12:58:07.593674 SAST | total-samples              12\n",
      "2021-07-16 12:58:07.594460 SAST | ------------------------  --------\n",
      "[-13.95787239 -13.95787239]\n",
      "2021-07-16 12:58:07.600997 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.602794 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.603450 SAST | mean-path-return_agent_0  -13.9579\n",
      "2021-07-16 12:58:07.604339 SAST | last-path-return_agent_0  -13.9579\n",
      "2021-07-16 12:58:07.605015 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.605667 SAST | mean-path-return_agent_1  -13.9579\n",
      "2021-07-16 12:58:07.606292 SAST | last-path-return_agent_1  -13.9579\n",
      "2021-07-16 12:58:07.606935 SAST | episodes                   13\n",
      "2021-07-16 12:58:07.608470 SAST | total-samples              13\n",
      "2021-07-16 12:58:07.609304 SAST | ------------------------  --------\n",
      "[-13.43270016 -13.43270016]\n",
      "2021-07-16 12:58:07.622658 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.623364 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.624008 SAST | mean-path-return_agent_0  -13.4327\n",
      "2021-07-16 12:58:07.624574 SAST | last-path-return_agent_0  -13.4327\n",
      "2021-07-16 12:58:07.625112 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.625634 SAST | mean-path-return_agent_1  -13.4327\n",
      "2021-07-16 12:58:07.626240 SAST | last-path-return_agent_1  -13.4327\n",
      "2021-07-16 12:58:07.631655 SAST | episodes                   14\n",
      "2021-07-16 12:58:07.633111 SAST | total-samples              14\n",
      "2021-07-16 12:58:07.633842 SAST | ------------------------  --------\n",
      "[-13.50445461 -13.50445461]\n",
      "2021-07-16 12:58:07.642333 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.642785 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.643233 SAST | mean-path-return_agent_0  -13.5045\n",
      "2021-07-16 12:58:07.645398 SAST | last-path-return_agent_0  -13.5045\n",
      "2021-07-16 12:58:07.646484 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.647334 SAST | mean-path-return_agent_1  -13.5045\n",
      "2021-07-16 12:58:07.648208 SAST | last-path-return_agent_1  -13.5045\n",
      "2021-07-16 12:58:07.649044 SAST | episodes                   15\n",
      "2021-07-16 12:58:07.651005 SAST | total-samples              15\n",
      "2021-07-16 12:58:07.651742 SAST | ------------------------  --------\n",
      "[-13.21770954 -13.21770954]\n",
      "2021-07-16 12:58:07.667996 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.668514 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.668937 SAST | mean-path-return_agent_0  -13.2177\n",
      "2021-07-16 12:58:07.669424 SAST | last-path-return_agent_0  -13.2177\n",
      "2021-07-16 12:58:07.671340 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.672437 SAST | mean-path-return_agent_1  -13.2177\n",
      "2021-07-16 12:58:07.674858 SAST | last-path-return_agent_1  -13.2177\n",
      "2021-07-16 12:58:07.676110 SAST | episodes                   16\n",
      "2021-07-16 12:58:07.677028 SAST | total-samples              16\n",
      "2021-07-16 12:58:07.678623 SAST | ------------------------  --------\n",
      "[-13.47707081 -13.47707081]\n",
      "2021-07-16 12:58:07.694056 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.695112 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.695945 SAST | mean-path-return_agent_0  -13.4771\n",
      "2021-07-16 12:58:07.696506 SAST | last-path-return_agent_0  -13.4771\n",
      "2021-07-16 12:58:07.697027 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.697529 SAST | mean-path-return_agent_1  -13.4771\n",
      "2021-07-16 12:58:07.699319 SAST | last-path-return_agent_1  -13.4771\n",
      "2021-07-16 12:58:07.700073 SAST | episodes                   17\n",
      "2021-07-16 12:58:07.700620 SAST | total-samples              17\n",
      "2021-07-16 12:58:07.701121 SAST | ------------------------  --------\n",
      "[-13.53369141 -13.53369141]\n",
      "2021-07-16 12:58:07.712862 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.713313 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.713722 SAST | mean-path-return_agent_0  -13.5337\n",
      "2021-07-16 12:58:07.714181 SAST | last-path-return_agent_0  -13.5337\n",
      "2021-07-16 12:58:07.714747 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.715226 SAST | mean-path-return_agent_1  -13.5337\n",
      "2021-07-16 12:58:07.715811 SAST | last-path-return_agent_1  -13.5337\n",
      "2021-07-16 12:58:07.716415 SAST | episodes                   18\n",
      "2021-07-16 12:58:07.716909 SAST | total-samples              18\n",
      "2021-07-16 12:58:07.717393 SAST | ------------------------  --------\n",
      "[-13.63942432 -13.63942432]\n",
      "2021-07-16 12:58:07.739769 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.740741 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.741330 SAST | mean-path-return_agent_0  -13.6394\n",
      "2021-07-16 12:58:07.741781 SAST | last-path-return_agent_0  -13.6394\n",
      "2021-07-16 12:58:07.743010 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.743556 SAST | mean-path-return_agent_1  -13.6394\n",
      "2021-07-16 12:58:07.744101 SAST | last-path-return_agent_1  -13.6394\n",
      "2021-07-16 12:58:07.744554 SAST | episodes                   19\n",
      "2021-07-16 12:58:07.744987 SAST | total-samples              19\n",
      "2021-07-16 12:58:07.745610 SAST | ------------------------  --------\n",
      "[-13.06963253 -13.06963253]\n",
      "2021-07-16 12:58:07.756929 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.757402 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.757749 SAST | mean-path-return_agent_0  -13.0696\n",
      "2021-07-16 12:58:07.758179 SAST | last-path-return_agent_0  -13.0696\n",
      "2021-07-16 12:58:07.758600 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.758964 SAST | mean-path-return_agent_1  -13.0696\n",
      "2021-07-16 12:58:07.759299 SAST | last-path-return_agent_1  -13.0696\n",
      "2021-07-16 12:58:07.759628 SAST | episodes                   20\n",
      "2021-07-16 12:58:07.759947 SAST | total-samples              20\n",
      "2021-07-16 12:58:07.760287 SAST | ------------------------  --------\n",
      "diff-ma_softq/2/MASQL_MASQL/2021-07-16 12:58:03.249936 \n",
      "[-13.42589474 -13.42589474]\n",
      "2021-07-16 12:58:07.767471 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.768014 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.768482 SAST | mean-path-return_agent_0  -13.4259\n",
      "2021-07-16 12:58:07.768891 SAST | last-path-return_agent_0  -13.4259\n",
      "2021-07-16 12:58:07.769232 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.770066 SAST | mean-path-return_agent_1  -13.4259\n",
      "2021-07-16 12:58:07.770445 SAST | last-path-return_agent_1  -13.4259\n",
      "2021-07-16 12:58:07.770777 SAST | episodes                   21\n",
      "2021-07-16 12:58:07.771108 SAST | total-samples              21\n",
      "2021-07-16 12:58:07.771469 SAST | ------------------------  --------\n",
      "[-13.29945087 -13.29945087]\n",
      "2021-07-16 12:58:07.785793 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.787295 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.787963 SAST | mean-path-return_agent_0  -13.2995\n",
      "2021-07-16 12:58:07.788639 SAST | last-path-return_agent_0  -13.2995\n",
      "2021-07-16 12:58:07.789057 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.789412 SAST | mean-path-return_agent_1  -13.2995\n",
      "2021-07-16 12:58:07.790066 SAST | last-path-return_agent_1  -13.2995\n",
      "2021-07-16 12:58:07.790527 SAST | episodes                   22\n",
      "2021-07-16 12:58:07.791004 SAST | total-samples              22\n",
      "2021-07-16 12:58:07.791485 SAST | ------------------------  --------\n",
      "[-14.29233456 -14.29233456]\n",
      "2021-07-16 12:58:07.797220 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.797672 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.798060 SAST | mean-path-return_agent_0  -14.2923\n",
      "2021-07-16 12:58:07.798593 SAST | last-path-return_agent_0  -14.2923\n",
      "2021-07-16 12:58:07.799266 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.800058 SAST | mean-path-return_agent_1  -14.2923\n",
      "2021-07-16 12:58:07.800585 SAST | last-path-return_agent_1  -14.2923\n",
      "2021-07-16 12:58:07.801157 SAST | episodes                   23\n",
      "2021-07-16 12:58:07.801766 SAST | total-samples              23\n",
      "2021-07-16 12:58:07.803247 SAST | ------------------------  --------\n",
      "[-14.60135555 -14.60135555]\n",
      "2021-07-16 12:58:07.811668 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.812409 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.812845 SAST | mean-path-return_agent_0  -14.6014\n",
      "2021-07-16 12:58:07.813226 SAST | last-path-return_agent_0  -14.6014\n",
      "2021-07-16 12:58:07.813536 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.813903 SAST | mean-path-return_agent_1  -14.6014\n",
      "2021-07-16 12:58:07.814226 SAST | last-path-return_agent_1  -14.6014\n",
      "2021-07-16 12:58:07.814523 SAST | episodes                   24\n",
      "2021-07-16 12:58:07.814831 SAST | total-samples              24\n",
      "2021-07-16 12:58:07.815125 SAST | ------------------------  --------\n",
      "[-13.63780499 -13.63780499]\n",
      "2021-07-16 12:58:07.825471 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.826103 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.826402 SAST | mean-path-return_agent_0  -13.6378\n",
      "2021-07-16 12:58:07.826688 SAST | last-path-return_agent_0  -13.6378\n",
      "2021-07-16 12:58:07.826941 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.827205 SAST | mean-path-return_agent_1  -13.6378\n",
      "2021-07-16 12:58:07.827454 SAST | last-path-return_agent_1  -13.6378\n",
      "2021-07-16 12:58:07.827732 SAST | episodes                   25\n",
      "2021-07-16 12:58:07.828010 SAST | total-samples              25\n",
      "2021-07-16 12:58:07.828274 SAST | ------------------------  --------\n",
      "[-13.72416115 -13.72416115]\n",
      "2021-07-16 12:58:07.837965 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.838706 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.839162 SAST | mean-path-return_agent_0  -13.7242\n",
      "2021-07-16 12:58:07.839549 SAST | last-path-return_agent_0  -13.7242\n",
      "2021-07-16 12:58:07.840037 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.840415 SAST | mean-path-return_agent_1  -13.7242\n",
      "2021-07-16 12:58:07.840837 SAST | last-path-return_agent_1  -13.7242\n",
      "2021-07-16 12:58:07.841304 SAST | episodes                   26\n",
      "2021-07-16 12:58:07.841722 SAST | total-samples              26\n",
      "2021-07-16 12:58:07.842168 SAST | ------------------------  --------\n",
      "[-13.16554928 -13.16554928]\n",
      "2021-07-16 12:58:07.858406 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.859173 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.860881 SAST | mean-path-return_agent_0  -13.1655\n",
      "2021-07-16 12:58:07.861926 SAST | last-path-return_agent_0  -13.1655\n",
      "2021-07-16 12:58:07.862798 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.863846 SAST | mean-path-return_agent_1  -13.1655\n",
      "2021-07-16 12:58:07.864794 SAST | last-path-return_agent_1  -13.1655\n",
      "2021-07-16 12:58:07.865725 SAST | episodes                   27\n",
      "2021-07-16 12:58:07.866551 SAST | total-samples              27\n",
      "2021-07-16 12:58:07.872220 SAST | ------------------------  --------\n",
      "[-13.53141785 -13.53141785]\n",
      "2021-07-16 12:58:07.888483 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.889222 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.889851 SAST | mean-path-return_agent_0  -13.5314\n",
      "2021-07-16 12:58:07.890369 SAST | last-path-return_agent_0  -13.5314\n",
      "2021-07-16 12:58:07.890846 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.891322 SAST | mean-path-return_agent_1  -13.5314\n",
      "2021-07-16 12:58:07.891749 SAST | last-path-return_agent_1  -13.5314\n",
      "2021-07-16 12:58:07.893231 SAST | episodes                   28\n",
      "2021-07-16 12:58:07.895948 SAST | total-samples              28\n",
      "2021-07-16 12:58:07.896625 SAST | ------------------------  --------\n",
      "[-13.07957935 -13.07957935]\n",
      "2021-07-16 12:58:07.916241 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.916904 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.917479 SAST | mean-path-return_agent_0  -13.0796\n",
      "2021-07-16 12:58:07.918036 SAST | last-path-return_agent_0  -13.0796\n",
      "2021-07-16 12:58:07.918579 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.919196 SAST | mean-path-return_agent_1  -13.0796\n",
      "2021-07-16 12:58:07.919848 SAST | last-path-return_agent_1  -13.0796\n",
      "2021-07-16 12:58:07.920480 SAST | episodes                   29\n",
      "2021-07-16 12:58:07.921136 SAST | total-samples              29\n",
      "2021-07-16 12:58:07.924726 SAST | ------------------------  --------\n",
      "[-13.35826397 -13.35826397]\n",
      "2021-07-16 12:58:07.934736 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.935277 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.935716 SAST | mean-path-return_agent_0  -13.3583\n",
      "2021-07-16 12:58:07.936170 SAST | last-path-return_agent_0  -13.3583\n",
      "2021-07-16 12:58:07.936563 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.936947 SAST | mean-path-return_agent_1  -13.3583\n",
      "2021-07-16 12:58:07.939690 SAST | last-path-return_agent_1  -13.3583\n",
      "2021-07-16 12:58:07.940451 SAST | episodes                   30\n",
      "2021-07-16 12:58:07.941332 SAST | total-samples              30\n",
      "2021-07-16 12:58:07.942865 SAST | ------------------------  --------\n",
      "diff-ma_softq/2/MASQL_MASQL/2021-07-16 12:58:03.249936 \n",
      "[-13.23230648 -13.23230648]\n",
      "2021-07-16 12:58:07.958942 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.963111 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.963686 SAST | mean-path-return_agent_0  -13.2323\n",
      "2021-07-16 12:58:07.967484 SAST | last-path-return_agent_0  -13.2323\n",
      "2021-07-16 12:58:07.968423 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.969464 SAST | mean-path-return_agent_1  -13.2323\n",
      "2021-07-16 12:58:07.970080 SAST | last-path-return_agent_1  -13.2323\n",
      "2021-07-16 12:58:07.970984 SAST | episodes                   31\n",
      "2021-07-16 12:58:07.971470 SAST | total-samples              31\n",
      "2021-07-16 12:58:07.971972 SAST | ------------------------  --------\n",
      "[-14.42969036 -14.42969036]\n",
      "2021-07-16 12:58:07.978964 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.979614 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.980094 SAST | mean-path-return_agent_0  -14.4297\n",
      "2021-07-16 12:58:07.980513 SAST | last-path-return_agent_0  -14.4297\n",
      "2021-07-16 12:58:07.981663 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.982120 SAST | mean-path-return_agent_1  -14.4297\n",
      "2021-07-16 12:58:07.982603 SAST | last-path-return_agent_1  -14.4297\n",
      "2021-07-16 12:58:07.983045 SAST | episodes                   32\n",
      "2021-07-16 12:58:07.983926 SAST | total-samples              32\n",
      "2021-07-16 12:58:07.984403 SAST | ------------------------  --------\n",
      "[-13.18118954 -13.18118954]\n",
      "2021-07-16 12:58:07.991595 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:07.992441 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:07.993916 SAST | mean-path-return_agent_0  -13.1812\n",
      "2021-07-16 12:58:07.994580 SAST | last-path-return_agent_0  -13.1812\n",
      "2021-07-16 12:58:07.995225 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:07.995818 SAST | mean-path-return_agent_1  -13.1812\n",
      "2021-07-16 12:58:07.996388 SAST | last-path-return_agent_1  -13.1812\n",
      "2021-07-16 12:58:07.997561 SAST | episodes                   33\n",
      "2021-07-16 12:58:07.998321 SAST | total-samples              33\n",
      "2021-07-16 12:58:07.998810 SAST | ------------------------  --------\n",
      "[-14.00095558 -14.00095558]\n",
      "2021-07-16 12:58:08.004736 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.005249 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.011640 SAST | mean-path-return_agent_0  -14.001\n",
      "2021-07-16 12:58:08.017426 SAST | last-path-return_agent_0  -14.001\n",
      "2021-07-16 12:58:08.018122 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.018735 SAST | mean-path-return_agent_1  -14.001\n",
      "2021-07-16 12:58:08.019311 SAST | last-path-return_agent_1  -14.001\n",
      "2021-07-16 12:58:08.019836 SAST | episodes                   34\n",
      "2021-07-16 12:58:08.020371 SAST | total-samples              34\n",
      "2021-07-16 12:58:08.020882 SAST | ------------------------  --------\n",
      "[-13.59117413 -13.59117413]\n",
      "2021-07-16 12:58:08.032578 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.033792 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.034395 SAST | mean-path-return_agent_0  -13.5912\n",
      "2021-07-16 12:58:08.034875 SAST | last-path-return_agent_0  -13.5912\n",
      "2021-07-16 12:58:08.035317 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.035786 SAST | mean-path-return_agent_1  -13.5912\n",
      "2021-07-16 12:58:08.036160 SAST | last-path-return_agent_1  -13.5912\n",
      "2021-07-16 12:58:08.036597 SAST | episodes                   35\n",
      "2021-07-16 12:58:08.036966 SAST | total-samples              35\n",
      "2021-07-16 12:58:08.038047 SAST | ------------------------  --------\n",
      "[-13.51807594 -13.51807594]\n",
      "2021-07-16 12:58:08.046513 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.048114 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.048897 SAST | mean-path-return_agent_0  -13.5181\n",
      "2021-07-16 12:58:08.049655 SAST | last-path-return_agent_0  -13.5181\n",
      "2021-07-16 12:58:08.050412 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.051122 SAST | mean-path-return_agent_1  -13.5181\n",
      "2021-07-16 12:58:08.051801 SAST | last-path-return_agent_1  -13.5181\n",
      "2021-07-16 12:58:08.052587 SAST | episodes                   36\n",
      "2021-07-16 12:58:08.053150 SAST | total-samples              36\n",
      "2021-07-16 12:58:08.053655 SAST | ------------------------  --------\n",
      "[-13.68295574 -13.68295574]\n",
      "2021-07-16 12:58:08.069388 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.069997 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.070609 SAST | mean-path-return_agent_0  -13.683\n",
      "2021-07-16 12:58:08.071202 SAST | last-path-return_agent_0  -13.683\n",
      "2021-07-16 12:58:08.071812 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.073228 SAST | mean-path-return_agent_1  -13.683\n",
      "2021-07-16 12:58:08.074119 SAST | last-path-return_agent_1  -13.683\n",
      "2021-07-16 12:58:08.074985 SAST | episodes                   37\n",
      "2021-07-16 12:58:08.076293 SAST | total-samples              37\n",
      "2021-07-16 12:58:08.077242 SAST | ------------------------  --------\n",
      "[-13.28046131 -13.28046131]\n",
      "2021-07-16 12:58:08.089146 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.089663 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.090149 SAST | mean-path-return_agent_0  -13.2805\n",
      "2021-07-16 12:58:08.090704 SAST | last-path-return_agent_0  -13.2805\n",
      "2021-07-16 12:58:08.091521 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.091896 SAST | mean-path-return_agent_1  -13.2805\n",
      "2021-07-16 12:58:08.092238 SAST | last-path-return_agent_1  -13.2805\n",
      "2021-07-16 12:58:08.092677 SAST | episodes                   38\n",
      "2021-07-16 12:58:08.093283 SAST | total-samples              38\n",
      "2021-07-16 12:58:08.095033 SAST | ------------------------  --------\n",
      "[-13.19324017 -13.19324017]\n",
      "2021-07-16 12:58:08.103740 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.104320 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.104930 SAST | mean-path-return_agent_0  -13.1932\n",
      "2021-07-16 12:58:08.105312 SAST | last-path-return_agent_0  -13.1932\n",
      "2021-07-16 12:58:08.105897 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.106353 SAST | mean-path-return_agent_1  -13.1932\n",
      "2021-07-16 12:58:08.106750 SAST | last-path-return_agent_1  -13.1932\n",
      "2021-07-16 12:58:08.107958 SAST | episodes                   39\n",
      "2021-07-16 12:58:08.108642 SAST | total-samples              39\n",
      "2021-07-16 12:58:08.109531 SAST | ------------------------  --------\n",
      "[-13.34646511 -13.34646511]\n",
      "2021-07-16 12:58:08.121031 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.121790 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.122397 SAST | mean-path-return_agent_0  -13.3465\n",
      "2021-07-16 12:58:08.123045 SAST | last-path-return_agent_0  -13.3465\n",
      "2021-07-16 12:58:08.123637 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.125144 SAST | mean-path-return_agent_1  -13.3465\n",
      "2021-07-16 12:58:08.125877 SAST | last-path-return_agent_1  -13.3465\n",
      "2021-07-16 12:58:08.126732 SAST | episodes                   40\n",
      "2021-07-16 12:58:08.127269 SAST | total-samples              40\n",
      "2021-07-16 12:58:08.127802 SAST | ------------------------  --------\n",
      "diff-ma_softq/2/MASQL_MASQL/2021-07-16 12:58:03.249936 \n",
      "[-12.98149014 -12.98149014]\n",
      "2021-07-16 12:58:08.141212 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.142280 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.143026 SAST | mean-path-return_agent_0  -12.9815\n",
      "2021-07-16 12:58:08.143675 SAST | last-path-return_agent_0  -12.9815\n",
      "2021-07-16 12:58:08.146653 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.147553 SAST | mean-path-return_agent_1  -12.9815\n",
      "2021-07-16 12:58:08.148539 SAST | last-path-return_agent_1  -12.9815\n",
      "2021-07-16 12:58:08.149439 SAST | episodes                   41\n",
      "2021-07-16 12:58:08.151124 SAST | total-samples              41\n",
      "2021-07-16 12:58:08.151798 SAST | ------------------------  --------\n",
      "[-13.39132595 -13.39132595]\n",
      "2021-07-16 12:58:08.176304 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.179667 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.180365 SAST | mean-path-return_agent_0  -13.3913\n",
      "2021-07-16 12:58:08.180847 SAST | last-path-return_agent_0  -13.3913\n",
      "2021-07-16 12:58:08.181552 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.183521 SAST | mean-path-return_agent_1  -13.3913\n",
      "2021-07-16 12:58:08.184428 SAST | last-path-return_agent_1  -13.3913\n",
      "2021-07-16 12:58:08.185220 SAST | episodes                   42\n",
      "2021-07-16 12:58:08.185756 SAST | total-samples              42\n",
      "2021-07-16 12:58:08.186319 SAST | ------------------------  --------\n",
      "[-13.67038631 -13.67038631]\n",
      "2021-07-16 12:58:08.201279 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.202071 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.202629 SAST | mean-path-return_agent_0  -13.6704\n",
      "2021-07-16 12:58:08.203077 SAST | last-path-return_agent_0  -13.6704\n",
      "2021-07-16 12:58:08.203798 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.204323 SAST | mean-path-return_agent_1  -13.6704\n",
      "2021-07-16 12:58:08.204739 SAST | last-path-return_agent_1  -13.6704\n",
      "2021-07-16 12:58:08.205134 SAST | episodes                   43\n",
      "2021-07-16 12:58:08.205546 SAST | total-samples              43\n",
      "2021-07-16 12:58:08.205942 SAST | ------------------------  --------\n",
      "[-13.83450317 -13.83450317]\n",
      "2021-07-16 12:58:08.212411 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.213047 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.213486 SAST | mean-path-return_agent_0  -13.8345\n",
      "2021-07-16 12:58:08.213836 SAST | last-path-return_agent_0  -13.8345\n",
      "2021-07-16 12:58:08.214198 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.214950 SAST | mean-path-return_agent_1  -13.8345\n",
      "2021-07-16 12:58:08.215304 SAST | last-path-return_agent_1  -13.8345\n",
      "2021-07-16 12:58:08.216273 SAST | episodes                   44\n",
      "2021-07-16 12:58:08.217388 SAST | total-samples              44\n",
      "2021-07-16 12:58:08.217875 SAST | ------------------------  --------\n",
      "[-13.16887856 -13.16887856]\n",
      "2021-07-16 12:58:08.229534 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.230113 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.230647 SAST | mean-path-return_agent_0  -13.1689\n",
      "2021-07-16 12:58:08.231130 SAST | last-path-return_agent_0  -13.1689\n",
      "2021-07-16 12:58:08.232177 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.232606 SAST | mean-path-return_agent_1  -13.1689\n",
      "2021-07-16 12:58:08.233220 SAST | last-path-return_agent_1  -13.1689\n",
      "2021-07-16 12:58:08.233618 SAST | episodes                   45\n",
      "2021-07-16 12:58:08.233995 SAST | total-samples              45\n",
      "2021-07-16 12:58:08.234381 SAST | ------------------------  --------\n",
      "[-13.7520237 -13.7520237]\n",
      "2021-07-16 12:58:08.248764 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.250068 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.250820 SAST | mean-path-return_agent_0  -13.752\n",
      "2021-07-16 12:58:08.251393 SAST | last-path-return_agent_0  -13.752\n",
      "2021-07-16 12:58:08.251854 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.252248 SAST | mean-path-return_agent_1  -13.752\n",
      "2021-07-16 12:58:08.252624 SAST | last-path-return_agent_1  -13.752\n",
      "2021-07-16 12:58:08.252974 SAST | episodes                   46\n",
      "2021-07-16 12:58:08.253289 SAST | total-samples              46\n",
      "2021-07-16 12:58:08.253619 SAST | ------------------------  --------\n",
      "[-13.50414753 -13.50414753]\n",
      "2021-07-16 12:58:08.259961 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.260384 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.260758 SAST | mean-path-return_agent_0  -13.5041\n",
      "2021-07-16 12:58:08.261115 SAST | last-path-return_agent_0  -13.5041\n",
      "2021-07-16 12:58:08.261453 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.261771 SAST | mean-path-return_agent_1  -13.5041\n",
      "2021-07-16 12:58:08.262090 SAST | last-path-return_agent_1  -13.5041\n",
      "2021-07-16 12:58:08.262426 SAST | episodes                   47\n",
      "2021-07-16 12:58:08.262744 SAST | total-samples              47\n",
      "2021-07-16 12:58:08.263053 SAST | ------------------------  --------\n",
      "[-13.2470808 -13.2470808]\n",
      "2021-07-16 12:58:08.268798 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.269293 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.269781 SAST | mean-path-return_agent_0  -13.2471\n",
      "2021-07-16 12:58:08.270132 SAST | last-path-return_agent_0  -13.2471\n",
      "2021-07-16 12:58:08.270473 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.271208 SAST | mean-path-return_agent_1  -13.2471\n",
      "2021-07-16 12:58:08.271535 SAST | last-path-return_agent_1  -13.2471\n",
      "2021-07-16 12:58:08.271890 SAST | episodes                   48\n",
      "2021-07-16 12:58:08.272210 SAST | total-samples              48\n",
      "2021-07-16 12:58:08.272548 SAST | ------------------------  --------\n",
      "[-13.42377663 -13.42377663]\n",
      "2021-07-16 12:58:08.282103 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.283553 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.284378 SAST | mean-path-return_agent_0  -13.4238\n",
      "2021-07-16 12:58:08.285570 SAST | last-path-return_agent_0  -13.4238\n",
      "2021-07-16 12:58:08.286309 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.286918 SAST | mean-path-return_agent_1  -13.4238\n",
      "2021-07-16 12:58:08.287505 SAST | last-path-return_agent_1  -13.4238\n",
      "2021-07-16 12:58:08.288199 SAST | episodes                   49\n",
      "2021-07-16 12:58:08.289099 SAST | total-samples              49\n",
      "2021-07-16 12:58:08.289674 SAST | ------------------------  --------\n",
      "[-13.16414642 -13.16414642]\n",
      "2021-07-16 12:58:08.304820 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.312322 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.313225 SAST | mean-path-return_agent_0  -13.1641\n",
      "2021-07-16 12:58:08.314178 SAST | last-path-return_agent_0  -13.1641\n",
      "2021-07-16 12:58:08.317007 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.317920 SAST | mean-path-return_agent_1  -13.1641\n",
      "2021-07-16 12:58:08.318910 SAST | last-path-return_agent_1  -13.1641\n",
      "2021-07-16 12:58:08.319626 SAST | episodes                   50\n",
      "2021-07-16 12:58:08.321408 SAST | total-samples              50\n",
      "2021-07-16 12:58:08.322379 SAST | ------------------------  --------\n",
      "diff-ma_softq/2/MASQL_MASQL/2021-07-16 12:58:03.249936 \n",
      "[-13.11886024 -13.11886024]\n",
      "2021-07-16 12:58:08.332176 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.333074 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.333713 SAST | mean-path-return_agent_0  -13.1189\n",
      "2021-07-16 12:58:08.334441 SAST | last-path-return_agent_0  -13.1189\n",
      "2021-07-16 12:58:08.334925 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.335387 SAST | mean-path-return_agent_1  -13.1189\n",
      "2021-07-16 12:58:08.336051 SAST | last-path-return_agent_1  -13.1189\n",
      "2021-07-16 12:58:08.336562 SAST | episodes                   51\n",
      "2021-07-16 12:58:08.337427 SAST | total-samples              51\n",
      "2021-07-16 12:58:08.337785 SAST | ------------------------  --------\n",
      "[-14.07553387 -14.07553387]\n",
      "2021-07-16 12:58:08.344037 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.344716 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.345294 SAST | mean-path-return_agent_0  -14.0755\n",
      "2021-07-16 12:58:08.345657 SAST | last-path-return_agent_0  -14.0755\n",
      "2021-07-16 12:58:08.346344 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.346713 SAST | mean-path-return_agent_1  -14.0755\n",
      "2021-07-16 12:58:08.347053 SAST | last-path-return_agent_1  -14.0755\n",
      "2021-07-16 12:58:08.347389 SAST | episodes                   52\n",
      "2021-07-16 12:58:08.347707 SAST | total-samples              52\n",
      "2021-07-16 12:58:08.348038 SAST | ------------------------  --------\n",
      "[-13.66660213 -13.66660213]\n",
      "2021-07-16 12:58:08.361881 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.362410 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.362793 SAST | mean-path-return_agent_0  -13.6666\n",
      "2021-07-16 12:58:08.363133 SAST | last-path-return_agent_0  -13.6666\n",
      "2021-07-16 12:58:08.363460 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.363860 SAST | mean-path-return_agent_1  -13.6666\n",
      "2021-07-16 12:58:08.364252 SAST | last-path-return_agent_1  -13.6666\n",
      "2021-07-16 12:58:08.364592 SAST | episodes                   53\n",
      "2021-07-16 12:58:08.364912 SAST | total-samples              53\n",
      "2021-07-16 12:58:08.365233 SAST | ------------------------  --------\n",
      "[-13.32597065 -13.32597065]\n",
      "2021-07-16 12:58:08.386008 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.389643 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.390971 SAST | mean-path-return_agent_0  -13.326\n",
      "2021-07-16 12:58:08.392040 SAST | last-path-return_agent_0  -13.326\n",
      "2021-07-16 12:58:08.392821 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.396108 SAST | mean-path-return_agent_1  -13.326\n",
      "2021-07-16 12:58:08.398842 SAST | last-path-return_agent_1  -13.326\n",
      "2021-07-16 12:58:08.399447 SAST | episodes                   54\n",
      "2021-07-16 12:58:08.399977 SAST | total-samples              54\n",
      "2021-07-16 12:58:08.400564 SAST | ------------------------  --------\n",
      "[-13.45187378 -13.45187378]\n",
      "2021-07-16 12:58:08.415811 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.419440 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.421588 SAST | mean-path-return_agent_0  -13.4519\n",
      "2021-07-16 12:58:08.425256 SAST | last-path-return_agent_0  -13.4519\n",
      "2021-07-16 12:58:08.425850 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.426280 SAST | mean-path-return_agent_1  -13.4519\n",
      "2021-07-16 12:58:08.426667 SAST | last-path-return_agent_1  -13.4519\n",
      "2021-07-16 12:58:08.427065 SAST | episodes                   55\n",
      "2021-07-16 12:58:08.427732 SAST | total-samples              55\n",
      "2021-07-16 12:58:08.431664 SAST | ------------------------  --------\n",
      "[-13.69773579 -13.69773579]\n",
      "2021-07-16 12:58:08.438888 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.443659 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.444546 SAST | mean-path-return_agent_0  -13.6977\n",
      "2021-07-16 12:58:08.445373 SAST | last-path-return_agent_0  -13.6977\n",
      "2021-07-16 12:58:08.445854 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.446291 SAST | mean-path-return_agent_1  -13.6977\n",
      "2021-07-16 12:58:08.446748 SAST | last-path-return_agent_1  -13.6977\n",
      "2021-07-16 12:58:08.447185 SAST | episodes                   56\n",
      "2021-07-16 12:58:08.447553 SAST | total-samples              56\n",
      "2021-07-16 12:58:08.447902 SAST | ------------------------  --------\n",
      "[-13.08841228 -13.08841228]\n",
      "2021-07-16 12:58:08.453593 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.454131 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.454513 SAST | mean-path-return_agent_0  -13.0884\n",
      "2021-07-16 12:58:08.454884 SAST | last-path-return_agent_0  -13.0884\n",
      "2021-07-16 12:58:08.455726 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.456086 SAST | mean-path-return_agent_1  -13.0884\n",
      "2021-07-16 12:58:08.456386 SAST | last-path-return_agent_1  -13.0884\n",
      "2021-07-16 12:58:08.456990 SAST | episodes                   57\n",
      "2021-07-16 12:58:08.457465 SAST | total-samples              57\n",
      "2021-07-16 12:58:08.457896 SAST | ------------------------  --------\n",
      "[-13.5120573 -13.5120573]\n",
      "2021-07-16 12:58:08.465529 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.470300 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.471618 SAST | mean-path-return_agent_0  -13.5121\n",
      "2021-07-16 12:58:08.472433 SAST | last-path-return_agent_0  -13.5121\n",
      "2021-07-16 12:58:08.473110 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.473903 SAST | mean-path-return_agent_1  -13.5121\n",
      "2021-07-16 12:58:08.474614 SAST | last-path-return_agent_1  -13.5121\n",
      "2021-07-16 12:58:08.476219 SAST | episodes                   58\n",
      "2021-07-16 12:58:08.477061 SAST | total-samples              58\n",
      "2021-07-16 12:58:08.478791 SAST | ------------------------  --------\n",
      "[-13.49768353 -13.49768353]\n",
      "2021-07-16 12:58:08.492218 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.493488 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.494523 SAST | mean-path-return_agent_0  -13.4977\n",
      "2021-07-16 12:58:08.495489 SAST | last-path-return_agent_0  -13.4977\n",
      "2021-07-16 12:58:08.496123 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.496697 SAST | mean-path-return_agent_1  -13.4977\n",
      "2021-07-16 12:58:08.497219 SAST | last-path-return_agent_1  -13.4977\n",
      "2021-07-16 12:58:08.498939 SAST | episodes                   59\n",
      "2021-07-16 12:58:08.499625 SAST | total-samples              59\n",
      "2021-07-16 12:58:08.500613 SAST | ------------------------  --------\n",
      "[-13.59163952 -13.59163952]\n",
      "2021-07-16 12:58:08.510175 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.511755 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.512671 SAST | mean-path-return_agent_0  -13.5916\n",
      "2021-07-16 12:58:08.513633 SAST | last-path-return_agent_0  -13.5916\n",
      "2021-07-16 12:58:08.514587 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.515806 SAST | mean-path-return_agent_1  -13.5916\n",
      "2021-07-16 12:58:08.517802 SAST | last-path-return_agent_1  -13.5916\n",
      "2021-07-16 12:58:08.518767 SAST | episodes                   60\n",
      "2021-07-16 12:58:08.519302 SAST | total-samples              60\n",
      "2021-07-16 12:58:08.519773 SAST | ------------------------  --------\n",
      "diff-ma_softq/2/MASQL_MASQL/2021-07-16 12:58:03.249936 \n",
      "[-14.08914948 -14.08914948]\n",
      "2021-07-16 12:58:08.534479 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.535729 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.539671 SAST | mean-path-return_agent_0  -14.0891\n",
      "2021-07-16 12:58:08.543648 SAST | last-path-return_agent_0  -14.0891\n",
      "2021-07-16 12:58:08.544220 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.544775 SAST | mean-path-return_agent_1  -14.0891\n",
      "2021-07-16 12:58:08.545299 SAST | last-path-return_agent_1  -14.0891\n",
      "2021-07-16 12:58:08.545663 SAST | episodes                   61\n",
      "2021-07-16 12:58:08.545986 SAST | total-samples              61\n",
      "2021-07-16 12:58:08.546306 SAST | ------------------------  --------\n",
      "[-13.97710896 -13.97710896]\n",
      "2021-07-16 12:58:08.552643 SAST | ------------------------  --------\n",
      "2021-07-16 12:58:08.560355 SAST | max-path-return_agent_0   -12.8808\n",
      "2021-07-16 12:58:08.561019 SAST | mean-path-return_agent_0  -13.9771\n",
      "2021-07-16 12:58:08.562662 SAST | last-path-return_agent_0  -13.9771\n",
      "2021-07-16 12:58:08.563667 SAST | max-path-return_agent_1   -12.8808\n",
      "2021-07-16 12:58:08.565595 SAST | mean-path-return_agent_1  -13.9771\n",
      "2021-07-16 12:58:08.566569 SAST | last-path-return_agent_1  -13.9771\n",
      "2021-07-16 12:58:08.567412 SAST | episodes                   62\n",
      "2021-07-16 12:58:08.568743 SAST | total-samples              62\n",
      "2021-07-16 12:58:08.569777 SAST | ------------------------  --------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}